{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicholassv/anaconda3/envs/thesis_linux_3.9/lib/python3.9/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "Downloading: \"https://download.pytorch.org/models/mnasnet0.5_top1_67.823-3ffadce67e.pth\" to /home/nicholassv/.cache/torch/hub/checkpoints/mnasnet0.5_top1_67.823-3ffadce67e.pth\n",
      "100%|██████████| 8.59M/8.59M [00:02<00:00, 3.49MB/s]\n"
     ]
    }
   ],
   "source": [
    "# a = torchvision.models.mobilenet_v3_small(torchvision.models.MobileNet_V3_Small_Weights.DEFAULT)\n",
    "# b = torchvision.models.shufflenet_v2_x1_0(torchvision.models.ShuffleNet_V2_X1_0_Weights.DEFAULT)\n",
    "# b = torchvision.models.shufflenet_v2_x0_5(torchvision.models.ShuffleNet_V2_X0_5_Weights.DEFAULT)\n",
    "c = torchvision.models.mnasnet0_5(torchvision.models.MNASNet0_5_Weights.DEFAULT)\n",
    "\n",
    "# resnet18_model = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.conv1[0] = torch.nn.Conv2d(2, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "b.fc = torch.nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.classifier = torch.nn.Identity()\n",
    "# a.features[0][0] =  torch.nn.Conv2d(2, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNASNet(\n",
       "  (layers): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(8, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "    (8): Sequential(\n",
       "      (0): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(8, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
       "          (4): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(16, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(48, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(16, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(48, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(16, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): Sequential(\n",
       "      (0): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(48, 48, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=48, bias=False)\n",
       "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(72, 72, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=72, bias=False)\n",
       "          (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(72, 72, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=72, bias=False)\n",
       "          (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): Sequential(\n",
       "      (0): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "          (4): BatchNorm2d(144, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (4): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (4): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): Sequential(\n",
       "      (0): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
       "          (4): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(240, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(288, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
       "          (4): BatchNorm2d(288, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): Sequential(\n",
       "      (0): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(288, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "          (4): BatchNorm2d(288, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (4): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (4): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (4): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (13): Sequential(\n",
       "      (0): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (4): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(160, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): Conv2d(160, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (15): BatchNorm2d(1280, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=True)\n",
       "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicholassv/anaconda3/envs/thesis_linux_3.9/lib/python3.9/site-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
      "/home/nicholassv/anaconda3/envs/thesis_linux_3.9/lib/python3.9/site-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return super().__sizeof__() + self.nbytes()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "MNASNet                                       [480, 1000]               --\n",
       "├─Sequential: 1-1                             [480, 1280, 7, 7]         --\n",
       "│    └─Conv2d: 2-1                            [480, 16, 112, 112]       432\n",
       "│    └─BatchNorm2d: 2-2                       [480, 16, 112, 112]       32\n",
       "│    └─ReLU: 2-3                              [480, 16, 112, 112]       --\n",
       "│    └─Conv2d: 2-4                            [480, 16, 112, 112]       144\n",
       "│    └─BatchNorm2d: 2-5                       [480, 16, 112, 112]       32\n",
       "│    └─ReLU: 2-6                              [480, 16, 112, 112]       --\n",
       "│    └─Conv2d: 2-7                            [480, 8, 112, 112]        128\n",
       "│    └─BatchNorm2d: 2-8                       [480, 8, 112, 112]        16\n",
       "│    └─Sequential: 2-9                        [480, 16, 56, 56]         --\n",
       "│    │    └─_InvertedResidual: 3-1            [480, 16, 56, 56]         920\n",
       "│    │    └─_InvertedResidual: 3-2            [480, 16, 56, 56]         2,192\n",
       "│    │    └─_InvertedResidual: 3-3            [480, 16, 56, 56]         2,192\n",
       "│    └─Sequential: 2-10                       [480, 24, 28, 28]         --\n",
       "│    │    └─_InvertedResidual: 3-4            [480, 24, 28, 28]         3,360\n",
       "│    │    └─_InvertedResidual: 3-5            [480, 24, 28, 28]         5,592\n",
       "│    │    └─_InvertedResidual: 3-6            [480, 24, 28, 28]         5,592\n",
       "│    └─Sequential: 2-11                       [480, 40, 14, 14]         --\n",
       "│    │    └─_InvertedResidual: 3-7            [480, 40, 14, 14]         13,472\n",
       "│    │    └─_InvertedResidual: 3-8            [480, 40, 14, 14]         26,240\n",
       "│    │    └─_InvertedResidual: 3-9            [480, 40, 14, 14]         26,240\n",
       "│    └─Sequential: 2-12                       [480, 48, 14, 14]         --\n",
       "│    │    └─_InvertedResidual: 3-10           [480, 48, 14, 14]         24,336\n",
       "│    │    └─_InvertedResidual: 3-11           [480, 48, 14, 14]         31,488\n",
       "│    └─Sequential: 2-13                       [480, 96, 7, 7]           --\n",
       "│    │    └─_InvertedResidual: 3-12           [480, 96, 7, 7]           50,016\n",
       "│    │    └─_InvertedResidual: 3-13           [480, 96, 7, 7]           127,488\n",
       "│    │    └─_InvertedResidual: 3-14           [480, 96, 7, 7]           127,488\n",
       "│    │    └─_InvertedResidual: 3-15           [480, 96, 7, 7]           127,488\n",
       "│    └─Sequential: 2-14                       [480, 160, 7, 7]          --\n",
       "│    │    └─_InvertedResidual: 3-16           [480, 160, 7, 7]          155,264\n",
       "│    └─Conv2d: 2-15                           [480, 1280, 7, 7]         204,800\n",
       "│    └─BatchNorm2d: 2-16                      [480, 1280, 7, 7]         2,560\n",
       "│    └─ReLU: 2-17                             [480, 1280, 7, 7]         --\n",
       "├─Sequential: 1-2                             [480, 1000]               --\n",
       "│    └─Dropout: 2-18                          [480, 1280]               --\n",
       "│    └─Linear: 2-19                           [480, 1000]               1,281,000\n",
       "===============================================================================================\n",
       "Total params: 2,218,512\n",
       "Trainable params: 2,218,512\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 50.15\n",
       "===============================================================================================\n",
       "Input size (MB): 289.01\n",
       "Forward/backward pass size (MB): 23546.42\n",
       "Params size (MB): 8.87\n",
       "Estimated Total Size (MB): 23844.31\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torchinfo.summary(c, input_size=(32*15,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicholassv/anaconda3/envs/thesis_linux_3.9/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import cv2\n",
    "import h5py\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import numpy\n",
    "import pandas\n",
    "import random\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "from importables.preprocessing_managers import PreprocessingManagers, DatasetDictionary, MaskGeneratorMocker, MotionVectorProcessorMocker\n",
    "from importables.utilities import Utilities\n",
    "from importables.custom_types import List, Tuple, Any, ndarray, Tensor, Union, MotionVectorFrame, OpticalFlowFrame, SegmentationMask, BoundingBoxXY1XY2, ColorXY\n",
    "from torchvision import transforms\n",
    "from importables.constants import SELECTED_NTU_DAILY_ACTIONS_SET, RANDOM_SEED_BYTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class FlowDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "                self, \n",
    "                dataset_mapping: dict, \n",
    "                label_encoder: sklearn.preprocessing.LabelEncoder, \n",
    "                loader: PreprocessingManagers.Loader, \n",
    "                dataframe: pandas.DataFrame, \n",
    "                h5py_base_file: h5py.File,  \n",
    "                timestep: int, \n",
    "                transform: Union[callable, None] = None, # type: ignore\n",
    "                label_key: str = \"A\",\n",
    "                with_pre_padding: bool = False\n",
    "        ):\n",
    "        \n",
    "        self.__timestep: int = timestep\n",
    "        self.__label_key: str = label_key\n",
    "        self.__h5py_base_file: h5py.File = h5py_base_file\n",
    "        self.__dataset_mapping: dict = dataset_mapping\n",
    "        self.__index_mapping: List[Tuple[str,int,int,int]] = []\n",
    "        self.__loader: PreprocessingManagers.Loader = loader\n",
    "        self.__transform:  Union[callable, None] = transform # type: ignore\n",
    "        self.__label_encoder: sklearn.preprocessing.LabelEncoder = label_encoder\n",
    "        self.__with_pre_padding: bool = with_pre_padding\n",
    "\n",
    "        for index in tqdm(range(len(dataframe)), desc=\"Generating index mapping...\"):\n",
    "\n",
    "            current_series: pandas.Series = dataframe.iloc[index]\n",
    "            label: int = current_series[self.__dataset_mapping[self.__label_key]] # type: ignore\n",
    "            frame_count: int = current_series[self.__dataset_mapping[DatasetDictionary.FRAME_COUNT_KEY]] # type: ignore\n",
    "            file_path: str = current_series[self.__dataset_mapping[DatasetDictionary.GENERATED_FILENAME_KEY]] # type: ignore\n",
    "\n",
    "            for frame_index in range(frame_count):\n",
    "                start_index: int = frame_index - self.__timestep + 1\n",
    "                stop_index: int = frame_index + 1\n",
    "                \n",
    "                if not self.__with_pre_padding:\n",
    "                    if start_index < 0:\n",
    "                        continue\n",
    "                    \n",
    "                self.__index_mapping.append(\n",
    "                        (\n",
    "                            file_path,\n",
    "                            label,\n",
    "                            start_index,\n",
    "                            stop_index,\n",
    "                        )\n",
    "                    )\n",
    "                \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.__index_mapping)\n",
    "\n",
    "    def __getitem__(self, idx: Any) -> dict:\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        file_path, label, start_index, stop_index = self.__index_mapping[idx]\n",
    "\n",
    "        file_group: h5py.Group = self.__h5py_base_file[file_path] # type: ignore\n",
    "        _, mask_generator, motion_vector_processor, optical_flow_generator = self.__loader.load_from_h5(file_group, start_index, stop_index) \n",
    "\n",
    "        label_label: ndarray = self.__label_encoder.transform([[label]])[0] # type: ignore\n",
    "        returns_list: List[dict[str, Union[ndarray, Tensor]]] = []\n",
    "\n",
    "        motion_vector_output: bool = motion_vector_processor is not None\n",
    "        optical_flow_output: bool = optical_flow_generator is not None\n",
    "\n",
    "        if self.__with_pre_padding:\n",
    "            if len(mask_generator) < self.__timestep:\n",
    "                padding_returns: dict[str, Union[ndarray, Tensor]] = {}\n",
    "                padding_returns[\"frame_label\"] = numpy.zeros_like(label_label)\n",
    "\n",
    "                if motion_vector_output:\n",
    "                    padding_returns[\"motion_vector\"] = motion_vector_processor.generate_blank()\n",
    "\n",
    "                if optical_flow_output:\n",
    "                    padding_returns[\"optical_flow\"] = optical_flow_generator.generate_blank()\n",
    "\n",
    "                if self.__transform:\n",
    "                    padding_returns = self.__transform(padding_returns)\n",
    "\n",
    "                returns_list = [padding_returns] * int(self.__timestep-len(mask_generator))\n",
    "\n",
    "        while len(mask_generator) > 0:\n",
    "            current_frame_returns: dict[str, Union[ndarray, Tensor]] = {}\n",
    "            current_frame_returns[\"frame_label\"] = numpy.zeros_like(label_label)\n",
    "\n",
    "            is_mask_available, segmentation_mask, bounding_box = mask_generator.forward_once_with_mcbb()\n",
    "            if is_mask_available:\n",
    "                current_frame_returns[\"frame_label\"] = label_label\n",
    "                current_frame_returns[\"segmentation_mask\"] = segmentation_mask\n",
    "                current_frame_returns[\"bounding_box\"] = bounding_box\n",
    "\n",
    "            if motion_vector_output:\n",
    "                motion_vector_frame: MotionVectorFrame = motion_vector_processor.process()\n",
    "                current_frame_returns[\"motion_vector\"] = motion_vector_frame\n",
    "\n",
    "            if optical_flow_output:\n",
    "                optical_flow_frame: OpticalFlowFrame = optical_flow_generator.forward_once_auto()\n",
    "                current_frame_returns[\"optical_flow\"] = optical_flow_frame\n",
    "\n",
    "            if self.__transform:\n",
    "                current_frame_returns = self.__transform(current_frame_returns)\n",
    "\n",
    "            if \"segmentation_mask\" in current_frame_returns:\n",
    "                del current_frame_returns[\"segmentation_mask\"]\n",
    "                del current_frame_returns[\"bounding_box\"]\n",
    "\n",
    "            returns_list.append(current_frame_returns)\n",
    "\n",
    "        collated_timestep: dict[str, Tensor] = torch.utils.data.default_collate(returns_list)\n",
    "        collated_timestep[\"label\"] = torch.tensor(label_label)\n",
    "\n",
    "        return collated_timestep\n",
    "    \n",
    "class FlowMaskCropTransform(object):\n",
    "    def __init__(self, mask: bool = True, crop: bool = True, replace_with: ColorXY = (128,128)) -> None:\n",
    "        self.__mask: bool = mask\n",
    "        self.__crop: bool = crop\n",
    "        self.__replace_with: ColorXY = replace_with\n",
    "    \n",
    "    def __call__(self, X: dict) -> dict:\n",
    "        if \"segmentation_mask\" not in X:\n",
    "            return X\n",
    "        \n",
    "        segmentation_mask: SegmentationMask = X[\"segmentation_mask\"]\n",
    "        bounding_box: BoundingBoxXY1XY2 = X[\"bounding_box\"]\n",
    "        \n",
    "        if self.__mask:\n",
    "            if \"motion_vector\" in X:\n",
    "                X[\"motion_vector\"][~segmentation_mask] = self.__replace_with\n",
    "\n",
    "            if \"optical_flow\" in X:\n",
    "                X[\"optical_flow\"][~segmentation_mask] = self.__replace_with\n",
    "            \n",
    "        if self.__crop:\n",
    "            if \"motion_vector\" in X:\n",
    "                X[\"motion_vector\"] = Utilities.crop_to_bb(X[\"motion_vector\"], bounding_box)\n",
    "\n",
    "            if \"optical_flow\" in X:\n",
    "                X[\"optical_flow\"] = Utilities.crop_to_bb(X[\"optical_flow\"], bounding_box)\n",
    "\n",
    "        del X[\"segmentation_mask\"]\n",
    "        del X[\"bounding_box\"]\n",
    "\n",
    "        return X\n",
    "    \n",
    "class FlowPadResize(object):\n",
    "    def __init__(self, output_size: int, pad_with: ColorXY = (128,128)) -> None:\n",
    "        self.__output_size: int = output_size\n",
    "        self.__pad_with: ColorXY = pad_with\n",
    "\n",
    "    def __call__(self, X: dict) -> dict:\n",
    "        \n",
    "        if \"motion_vector\" in X:\n",
    "            X[\"motion_vector\"],_,_,_,_,_ = Utilities.letterbox(X[\"motion_vector\"], self.__output_size, self.__pad_with, 0, True)\n",
    "\n",
    "        if \"optical_flow\" in X:\n",
    "            X[\"optical_flow\"],_,_,_,_,_ = Utilities.letterbox(X[\"optical_flow\"], self.__output_size, self.__pad_with, 0, True)\n",
    "\n",
    "        return X\n",
    "        \n",
    "class FlowToCHW(object):\n",
    "\n",
    "    def __call__(self, X: dict) -> dict:\n",
    "        \n",
    "        if \"motion_vector\" in X:\n",
    "            X[\"motion_vector\"] = X[\"motion_vector\"].transpose((2, 0, 1))\n",
    "\n",
    "        if \"optical_flow\" in X:\n",
    "            X[\"optical_flow\"] =  X[\"optical_flow\"].transpose((2, 0, 1))\n",
    "\n",
    "        return X\n",
    "    \n",
    "class FlowRescale(object):\n",
    "    \n",
    "    def __init__(self, scale: float = 1.0) -> None:\n",
    "        self.__scale: float = scale\n",
    "\n",
    "    def __call__(self, X: dict) -> dict:\n",
    "         \n",
    "        if \"motion_vector\" in X:\n",
    "            X[\"motion_vector\"] = (X[\"motion_vector\"] * self.__scale).astype(numpy.float32)\n",
    "\n",
    "        if \"optical_flow\" in X:\n",
    "            X[\"optical_flow\"] = (X[\"optical_flow\"] * self.__scale).astype(numpy.float32)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seed():\n",
    "    random.seed(RANDOM_SEED_BYTES)\n",
    "    numpy.random.seed(int.from_bytes(RANDOM_SEED_BYTES[:4], \"big\"))\n",
    "    torch.manual_seed(int.from_bytes(RANDOM_SEED_BYTES[:4], \"big\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_mapping = DatasetDictionary.Mappings.NTU_ACTION_RECOGNITION_DATASET\n",
    "pd_pregen = DatasetDictionary(\"/mnt/c/Skripsi/dataset-pregen/generated_dictionary.csv\",DatasetDictionary.Mappings.NTU_ACTION_RECOGNITION_DATASET).as_DataFrame()\n",
    "pd_pregen_filter = pd_pregen.loc[pd_pregen[curr_mapping[\"A\"]].isin(list(SELECTED_NTU_DAILY_ACTIONS_SET)[:5])]\n",
    "pd_pregen_filter = pd_pregen_filter.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActionID</th>\n",
       "      <th>CameraID</th>\n",
       "      <th>PerformerID</th>\n",
       "      <th>ReplicationID</th>\n",
       "      <th>SetupID</th>\n",
       "      <th>SourceFilePath</th>\n",
       "      <th>GeneratedFileName</th>\n",
       "      <th>FrameCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>../../dataset-h264/R001A002/S001C001P002R001A0...</td>\n",
       "      <td>S001C001P002R001A002_rgb.h5</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>../../dataset-h264/R001A002/S001C001P003R001A0...</td>\n",
       "      <td>S001C001P003R001A002_rgb.h5</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>../../dataset-h264/R001A002/S001C001P004R001A0...</td>\n",
       "      <td>S001C001P004R001A002_rgb.h5</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>../../dataset-h264/R001A002/S001C001P005R001A0...</td>\n",
       "      <td>S001C001P005R001A002_rgb.h5</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>../../dataset-h264/R001A002/S001C001P006R001A0...</td>\n",
       "      <td>S001C001P006R001A002_rgb.h5</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4758</th>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>../../dataset-h264/R002A070/S032C003P102R002A0...</td>\n",
       "      <td>S032C003P102R002A070_rgb.h5</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4759</th>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>../../dataset-h264/R002A070/S032C003P103R002A0...</td>\n",
       "      <td>S032C003P103R002A070_rgb.h5</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4760</th>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>../../dataset-h264/R002A070/S032C003P104R002A0...</td>\n",
       "      <td>S032C003P104R002A070_rgb.h5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4761</th>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>../../dataset-h264/R002A070/S032C003P105R002A0...</td>\n",
       "      <td>S032C003P105R002A070_rgb.h5</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4762</th>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>../../dataset-h264/R002A070/S032C003P106R002A0...</td>\n",
       "      <td>S032C003P106R002A070_rgb.h5</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4763 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ActionID  CameraID  PerformerID  ReplicationID  SetupID  \\\n",
       "0            2         1            2              1        1   \n",
       "1            2         1            3              1        1   \n",
       "2            2         1            4              1        1   \n",
       "3            2         1            5              1        1   \n",
       "4            2         1            6              1        1   \n",
       "...        ...       ...          ...            ...      ...   \n",
       "4758        70         3          102              2       32   \n",
       "4759        70         3          103              2       32   \n",
       "4760        70         3          104              2       32   \n",
       "4761        70         3          105              2       32   \n",
       "4762        70         3          106              2       32   \n",
       "\n",
       "                                         SourceFilePath  \\\n",
       "0     ../../dataset-h264/R001A002/S001C001P002R001A0...   \n",
       "1     ../../dataset-h264/R001A002/S001C001P003R001A0...   \n",
       "2     ../../dataset-h264/R001A002/S001C001P004R001A0...   \n",
       "3     ../../dataset-h264/R001A002/S001C001P005R001A0...   \n",
       "4     ../../dataset-h264/R001A002/S001C001P006R001A0...   \n",
       "...                                                 ...   \n",
       "4758  ../../dataset-h264/R002A070/S032C003P102R002A0...   \n",
       "4759  ../../dataset-h264/R002A070/S032C003P103R002A0...   \n",
       "4760  ../../dataset-h264/R002A070/S032C003P104R002A0...   \n",
       "4761  ../../dataset-h264/R002A070/S032C003P105R002A0...   \n",
       "4762  ../../dataset-h264/R002A070/S032C003P106R002A0...   \n",
       "\n",
       "                GeneratedFileName  FrameCount  \n",
       "0     S001C001P002R001A002_rgb.h5          88  \n",
       "1     S001C001P003R001A002_rgb.h5         110  \n",
       "2     S001C001P004R001A002_rgb.h5         133  \n",
       "3     S001C001P005R001A002_rgb.h5          64  \n",
       "4     S001C001P006R001A002_rgb.h5          73  \n",
       "...                           ...         ...  \n",
       "4758  S032C003P102R002A070_rgb.h5          53  \n",
       "4759  S032C003P103R002A070_rgb.h5          46  \n",
       "4760  S032C003P104R002A070_rgb.h5          31  \n",
       "4761  S032C003P105R002A070_rgb.h5          48  \n",
       "4762  S032C003P106R002A070_rgb.h5          43  \n",
       "\n",
       "[4763 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_pregen_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IntegerArray>\n",
       "[2, 16, 20, 68, 70]\n",
       "Length: 5, dtype: Int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_pregen_filter[curr_mapping[\"A\"]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 16, 20, 68, 70])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pregen_enc = sklearn.preprocessing.LabelEncoder().fit(numpy.expand_dims(pd_pregen_filter[curr_mapping[\"A\"]].astype(int).unique(),1))\n",
    "pregen_enc.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pregen_enc.transform([[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only subset of data\n",
    "set_all_seed()\n",
    "_, pd_pregen_filter = sklearn.model_selection.train_test_split(pd_pregen_filter, test_size =0.1, shuffle=True, stratify=pd_pregen_filter[curr_mapping[\"A\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all_seed()\n",
    "train_pd, test_pd = sklearn.model_selection.train_test_split(pd_pregen_filter, test_size =0.3, shuffle=True, stratify=pd_pregen_filter[curr_mapping[\"A\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActionID</th>\n",
       "      <th>CameraID</th>\n",
       "      <th>PerformerID</th>\n",
       "      <th>ReplicationID</th>\n",
       "      <th>SetupID</th>\n",
       "      <th>SourceFilePath</th>\n",
       "      <th>GeneratedFileName</th>\n",
       "      <th>FrameCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>../../dataset-h264/R002A020/S001C003P001R002A0...</td>\n",
       "      <td>S001C003P001R002A020_rgb.h5</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>../../dataset-h264/R001A068/S030C002P075R001A0...</td>\n",
       "      <td>S030C002P075R001A068_rgb.h5</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>../../dataset-h264/R002A002/S008C003P025R002A0...</td>\n",
       "      <td>S008C003P025R002A002_rgb.h5</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>../../dataset-h264/R002A016/S012C002P018R002A0...</td>\n",
       "      <td>S012C002P018R002A016_rgb.h5</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>../../dataset-h264/R002A002/S012C002P007R002A0...</td>\n",
       "      <td>S012C002P007R002A002_rgb.h5</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>../../dataset-h264/R001A068/S028C001P041R001A0...</td>\n",
       "      <td>S028C001P041R001A068_rgb.h5</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>../../dataset-h264/R001A020/S009C003P019R001A0...</td>\n",
       "      <td>S009C003P019R001A020_rgb.h5</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>../../dataset-h264/R001A016/S006C003P023R001A0...</td>\n",
       "      <td>S006C003P023R001A016_rgb.h5</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>../../dataset-h264/R001A002/S010C002P019R001A0...</td>\n",
       "      <td>S010C002P019R001A002_rgb.h5</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>../../dataset-h264/R001A070/S022C001P067R001A0...</td>\n",
       "      <td>S022C001P067R001A070_rgb.h5</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ActionID  CameraID  PerformerID  ReplicationID  SetupID  \\\n",
       "0          20         3            1              2        1   \n",
       "1          68         2           75              1       30   \n",
       "2           2         3           25              2        8   \n",
       "3          16         2           18              2       12   \n",
       "4           2         2            7              2       12   \n",
       "..        ...       ...          ...            ...      ...   \n",
       "139        68         1           41              1       28   \n",
       "140        20         3           19              1        9   \n",
       "141        16         3           23              1        6   \n",
       "142         2         2           19              1       10   \n",
       "143        70         1           67              1       22   \n",
       "\n",
       "                                        SourceFilePath  \\\n",
       "0    ../../dataset-h264/R002A020/S001C003P001R002A0...   \n",
       "1    ../../dataset-h264/R001A068/S030C002P075R001A0...   \n",
       "2    ../../dataset-h264/R002A002/S008C003P025R002A0...   \n",
       "3    ../../dataset-h264/R002A016/S012C002P018R002A0...   \n",
       "4    ../../dataset-h264/R002A002/S012C002P007R002A0...   \n",
       "..                                                 ...   \n",
       "139  ../../dataset-h264/R001A068/S028C001P041R001A0...   \n",
       "140  ../../dataset-h264/R001A020/S009C003P019R001A0...   \n",
       "141  ../../dataset-h264/R001A016/S006C003P023R001A0...   \n",
       "142  ../../dataset-h264/R001A002/S010C002P019R001A0...   \n",
       "143  ../../dataset-h264/R001A070/S022C001P067R001A0...   \n",
       "\n",
       "               GeneratedFileName  FrameCount  \n",
       "0    S001C003P001R002A020_rgb.h5         104  \n",
       "1    S030C002P075R001A068_rgb.h5          76  \n",
       "2    S008C003P025R002A002_rgb.h5          79  \n",
       "3    S012C002P018R002A016_rgb.h5          97  \n",
       "4    S012C002P007R002A002_rgb.h5         119  \n",
       "..                           ...         ...  \n",
       "139  S028C001P041R001A068_rgb.h5          41  \n",
       "140  S009C003P019R001A020_rgb.h5          65  \n",
       "141  S006C003P023R001A016_rgb.h5         217  \n",
       "142  S010C002P019R001A002_rgb.h5          75  \n",
       "143  S022C001P067R001A070_rgb.h5          25  \n",
       "\n",
       "[144 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pd.reset_index(drop = True)\n",
    "test_pd.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70    67\n",
       "68    67\n",
       "2     67\n",
       "16    66\n",
       "20    66\n",
       "Name: ActionID, dtype: Int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pd.ActionID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20    29\n",
       "68    29\n",
       "16    29\n",
       "70    29\n",
       "2     28\n",
       "Name: ActionID, dtype: Int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pd.ActionID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5py_instance = h5py.File(\"/mnt/c/Skripsi/dataset-pregen/generated_consolidation.h5\", swmr=True, rdcc_nbytes=1024**2*4000, rdcc_nslots=1e7)\n",
    "args_mvprocessor = {\n",
    "    \"raw_motion_vectors\": False,\n",
    "    \"target_size\": 418,\n",
    "}\n",
    "\n",
    "args_maskgenerator = {\n",
    "    \"weight_path\": './libs/yolov7-mask/yolov7-mask.pt',\n",
    "    \"hyperparameter_path\": './libs/yolov7-mask/data/hyp.scratch.mask.yaml',\n",
    "    \"confidence_threshold\": 0.5,\n",
    "    \"iou_threshold\": 0.45,\n",
    "    \"target_size\": 418,\n",
    "    \"optimize_model\": True,\n",
    "    \"bounding_box_grouping_range_scale\": 10\n",
    "}\n",
    "\n",
    "loader = PreprocessingManagers.Loader(DatasetDictionary.Mappings.NTU_ACTION_RECOGNITION_DATASET, args_maskgenerator, args_mvprocessor, None)\n",
    "timestep = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06bef49cc8f4e948df05f0a9b917944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating index mapping...:   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a919e824ef304f15b83197b43df3f97a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating index mapping...:   0%|          | 0/144 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = FlowDataset(\n",
    "    DatasetDictionary.Mappings.NTU_ACTION_RECOGNITION_DATASET,\n",
    "    pregen_enc,\n",
    "    loader,\n",
    "    train_pd,\n",
    "    h5py_instance,\n",
    "    timestep,\n",
    "    transforms.Compose([\n",
    "        FlowMaskCropTransform(),\n",
    "        FlowPadResize(224),\n",
    "        FlowToCHW(),\n",
    "        FlowRescale(1/255.)\n",
    "    ])\n",
    "    )\n",
    "\n",
    "test_ds = FlowDataset(\n",
    "    DatasetDictionary.Mappings.NTU_ACTION_RECOGNITION_DATASET,\n",
    "    pregen_enc,\n",
    "    loader,\n",
    "    test_pd,\n",
    "    h5py_instance,\n",
    "    timestep,\n",
    "    transforms.Compose([\n",
    "        FlowMaskCropTransform(),\n",
    "        FlowPadResize(224),\n",
    "        FlowToCHW(),\n",
    "        FlowRescale(1/255.)\n",
    "    ])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frame_label': tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]),\n",
       " 'motion_vector': tensor([[[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           ...,\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
       " \n",
       "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           ...,\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
       " \n",
       " \n",
       "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           ...,\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
       " \n",
       "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           ...,\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
       " \n",
       " \n",
       "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           ...,\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
       " \n",
       "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           ...,\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           ...,\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
       " \n",
       "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           ...,\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
       " \n",
       " \n",
       "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           ...,\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
       " \n",
       "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           ...,\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
       " \n",
       " \n",
       "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           ...,\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
       " \n",
       "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           ...,\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]]]),\n",
       " 'label': tensor(4)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(train_ds):\n",
    "#     i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = torch.get_num_threads()\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, BATCH_SIZE, num_workers=3, shuffle= True)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, BATCH_SIZE, num_workers=3, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9acbf1e85084c8d9ad3e48d5eaa5ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'frame_label': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'motion_vector': tensor([[[[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
      "\n",
      "\n",
      "         [[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
      "\n",
      "          [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           ...,\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
      "           [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]]]]), 'label': tensor([1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 3, 0, 1, 1, 1, 0])}\n"
     ]
    }
   ],
   "source": [
    "for x in tqdm(train_dl):\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models\n",
    "import torch.functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet18_model = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
    "# resnet18_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet18_model.conv1 = torch.nn.Conv2d(2, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "# resnet18_model.fc = torch.nn.Identity()\n",
    "# resnet18_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for x in train_dl:\n",
    "    print(x[\"motion_vector\"][:,0,...].shape)\n",
    "    # print(resnet18_model(x[\"motion_vector\"][:,0,...]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet18_model(x[\"motion_vector\"][:,0,...]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class HARMVModelCNNLSTMv1(torch.nn.Module):\n",
    "#     def __init__(self, category_count: int, timesteps: int, lstm_hidden: int = 64) -> None:\n",
    "#         super(HARMVModelCNNLSTMv1, self).__init__()\n",
    "#         self.__lstm_hidden: int = lstm_hidden\n",
    "#         self.__timesteps: int = timesteps\n",
    "#         self.resnet18_model = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
    "#         self.resnet18_model.conv1 = torch.nn.Conv2d(2, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "#         self.resnet18_model.fc = torch.nn.Identity()\n",
    "#         self.resnet18_model = self.resnet18_model.requires_grad_(False)\n",
    "#         self.resnet18_model = self.resnet18_model.eval()\n",
    "#         self.lstm1 = torch.nn.LSTM(512,  self.__lstm_hidden, bidirectional=True, batch_first=True)\n",
    "#         self.lstm2 = torch.nn.LSTM( self.__lstm_hidden * 2,  self.__lstm_hidden, bidirectional=True, batch_first=True)\n",
    "#         self.fc1_frame = torch.nn.Linear( self.__lstm_hidden*2,  self.__lstm_hidden*2)\n",
    "#         self.fc2_frame = torch.nn.Linear( self.__lstm_hidden*2, category_count)\n",
    "#         self.fc1_global = torch.nn.Linear( self.__lstm_hidden * 2*self.__timesteps,  self.__lstm_hidden*2)\n",
    "#         self.fc2_global = torch.nn.Linear( self.__lstm_hidden*2, category_count)\n",
    "\n",
    "#     def forward(self, x: Tensor):\n",
    "#         batch_size, timesteps, C, H, W = x.shape\n",
    "#         assert self.__timesteps == timesteps, f\"Timesteps not equal to {self.__timesteps}\"\n",
    "#         with torch.no_grad():\n",
    "#             x = x.view(batch_size * self.__timesteps, C, H, W)\n",
    "#             x = self.resnet18_model(x)\n",
    "#             x = x.view(batch_size, self.__timesteps, -1)\n",
    "            \n",
    "#         self.lstm1.flatten_parameters()\n",
    "#         x, _, _ = self.lstm1(x)\n",
    "#         self.lstm2.flatten_parameters()\n",
    "#         x, _, _ = self.lstm2(x)\n",
    "#         x = x.contiguous()\n",
    "\n",
    "#         x_frame = x.view(batch_size * self.__timesteps,  self.__lstm_hidden * 2)\n",
    "#         x_frame = torch.nn.functional.relu(self.fc1_frame(x_frame))\n",
    "#         x_frame = torch.nn.functional.softmax(self.fc2_frame(x_frame), dim=1)\n",
    "#         x_frame = x_frame.view(batch_size, timesteps, -1)\n",
    "\n",
    "#         x_global = x.view(batch_size, -1)\n",
    "#         x_global = torch.nn.functional.relu(self.fc1_global(x_global))\n",
    "#         x_global = torch.nn.functional.softmax(self.fc2_global(x_global), dim=1)\n",
    "\n",
    "#         return {\"frame\": x_frame, \"global\": x_global}\n",
    "\n",
    "\n",
    "class HARMVModelCNNLSTMv1(torch.nn.Module):\n",
    "    def __init__(self, category_count: int, timesteps: int, lstm_hidden: int = 64) -> None:\n",
    "        super(HARMVModelCNNLSTMv1, self).__init__()\n",
    "        self.__lstm_hidden: int = lstm_hidden\n",
    "        self.__timesteps: int = timesteps\n",
    "        self.resnet18_model = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
    "        self.resnet18_model.conv1 = torch.nn.Conv2d(2, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.resnet18_model.fc = torch.nn.Identity()\n",
    "        self.resnet18_model = self.resnet18_model.requires_grad_(False)\n",
    "        self.resnet18_model = self.resnet18_model.eval()\n",
    "        self.lstm1 = torch.nn.LSTM(512,  self.__lstm_hidden, bidirectional=True, batch_first=True)\n",
    "        self.lstm2 = torch.nn.LSTM( self.__lstm_hidden * 2,  self.__lstm_hidden, bidirectional=True, batch_first=True)\n",
    "        self.fc1 = torch.nn.Linear( self.__lstm_hidden*2,  self.__lstm_hidden*4)\n",
    "        self.fc2 = torch.nn.Linear( self.__lstm_hidden*4,  self.__lstm_hidden*2)\n",
    "        self.fc3 = torch.nn.Linear( self.__lstm_hidden*2, category_count)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        batch_size, timesteps, C, H, W = x.shape\n",
    "        assert self.__timesteps == timesteps, f\"Timesteps not equal to {self.__timesteps}\"\n",
    "        with torch.no_grad():\n",
    "            x = x.view(batch_size * self.__timesteps, C, H, W)\n",
    "            x = self.resnet18_model(x)\n",
    "            x = x.view(batch_size, self.__timesteps, -1)\n",
    "            \n",
    "        self.lstm1.flatten_parameters()\n",
    "        lo, (x, _) = self.lstm1(x)\n",
    "        self.lstm2.flatten_parameters()\n",
    "        _, (x, _) = self.lstm2(lo)\n",
    "\n",
    "        x = torch.cat((x[0],x[1]), dim = 1)\n",
    "\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = HARMVModelCNNLSTMv1(len(pregen_enc.classes_), timestep, 128)\n",
    "test_model = test_model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "HARMVModelCNNLSTMv1                           [16, 5]                   --\n",
       "├─ResNet: 1-1                                 [384, 512]                --\n",
       "│    └─Conv2d: 2-1                            [384, 64, 112, 112]       (6,272)\n",
       "│    └─BatchNorm2d: 2-2                       [384, 64, 112, 112]       (128)\n",
       "│    └─ReLU: 2-3                              [384, 64, 112, 112]       --\n",
       "│    └─MaxPool2d: 2-4                         [384, 64, 56, 56]         --\n",
       "│    └─Sequential: 2-5                        [384, 64, 56, 56]         --\n",
       "│    │    └─BasicBlock: 3-1                   [384, 64, 56, 56]         (73,984)\n",
       "│    │    └─BasicBlock: 3-2                   [384, 64, 56, 56]         (73,984)\n",
       "│    └─Sequential: 2-6                        [384, 128, 28, 28]        --\n",
       "│    │    └─BasicBlock: 3-3                   [384, 128, 28, 28]        (230,144)\n",
       "│    │    └─BasicBlock: 3-4                   [384, 128, 28, 28]        (295,424)\n",
       "│    └─Sequential: 2-7                        [384, 256, 14, 14]        --\n",
       "│    │    └─BasicBlock: 3-5                   [384, 256, 14, 14]        (919,040)\n",
       "│    │    └─BasicBlock: 3-6                   [384, 256, 14, 14]        (1,180,672)\n",
       "│    └─Sequential: 2-8                        [384, 512, 7, 7]          --\n",
       "│    │    └─BasicBlock: 3-7                   [384, 512, 7, 7]          (3,673,088)\n",
       "│    │    └─BasicBlock: 3-8                   [384, 512, 7, 7]          (4,720,640)\n",
       "│    └─AdaptiveAvgPool2d: 2-9                 [384, 512, 1, 1]          --\n",
       "│    └─Identity: 2-10                         [384, 512]                --\n",
       "├─LSTM: 1-2                                   [16, 24, 256]             657,408\n",
       "├─LSTM: 1-3                                   [16, 24, 256]             395,264\n",
       "├─Linear: 1-4                                 [16, 512]                 131,584\n",
       "├─Linear: 1-5                                 [16, 256]                 131,328\n",
       "├─Linear: 1-6                                 [16, 5]                   1,285\n",
       "===============================================================================================\n",
       "Total params: 12,490,245\n",
       "Trainable params: 1,316,869\n",
       "Non-trainable params: 11,173,376\n",
       "Total mult-adds (G): 681.71\n",
       "===============================================================================================\n",
       "Input size (MB): 154.14\n",
       "Forward/backward pass size (MB): 15261.60\n",
       "Params size (MB): 49.96\n",
       "Estimated Total Size (MB): 15465.70\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "torchinfo.summary(test_model,input_data=x[\"motion_vector\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model(x[\"motion_vector\"].to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115cac65af01452b9955043d399679db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ca731a9cdf499981e4eacbfcd15aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/581 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded0869e966e4c4c957b260cd6e5f8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d05e0919194c6890aaac996a6ec472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/581 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e0d93cc3324aef9fcc894548bf984d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19689/1413855010.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mloss_sum_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0macc_sum_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"motion_vector\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mglobal_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis_linux_3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis_linux_3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis_linux_3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis_linux_3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis_linux_3.9/lib/python3.9/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis_linux_3.9/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis_linux_3.9/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis_linux_3.9/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis_linux_3.9/lib/python3.9/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set_all_seed()\n",
    "# from IPython.display import clear_output\n",
    "# import torch.utils.tensorboard.writer\n",
    "# writer = torch.utils.tensorboard.writer.SummaryWriter()\n",
    "# criterion_frame = torch.nn.CrossEntropyLoss()\n",
    "# criterion_global = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(test_model.parameters(), lr=0.001)\n",
    "# EPOCH = 2\n",
    "# for e in range(EPOCH):\n",
    "#     for data in tqdm(train_dl):\n",
    "#         inputs = data[\"motion_vector\"].to(\"cuda\")\n",
    "#         frame_labels = data[\"frame_label\"].float().to(\"cuda\").view(BATCH_SIZE*timestep,-1)\n",
    "#         global_labels = data[\"label\"].float().to(\"cuda\")\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = test_model(inputs)\n",
    "#         output_frame = outputs[\"frame\"].view(BATCH_SIZE*timestep,-1)\n",
    "#         output_global = outputs[\"global\"]\n",
    "#         loss_frame = criterion_frame(output_frame, frame_labels)\n",
    "#         loss_global = criterion_global(output_global, global_labels)\n",
    "#         writer.add_scalar(\"Loss-frame/train\", loss_frame, e)\n",
    "#         writer.add_scalar(\"Loss-global/train\", loss_global, e)\n",
    "#         sum_loss = loss_frame + loss_global\n",
    "#         sum_loss.backward()\n",
    "#         optimizer.step()\n",
    "#         output_frame_b = (output_frame>0.5).float()\n",
    "#         correct_frame = (output_frame_b == frame_labels).float().sum()\n",
    "#         output_global_b = (output_global>0.5).float()\n",
    "#         correct_global = (output_global_b == global_labels).float().sum()\n",
    "#         writer.add_scalar(\"Accuracy-frame/train\", correct_frame/(BATCH_SIZE*timestep), e)\n",
    "#         writer.add_scalar(\"Accuracy-global/train\", correct_global/BATCH_SIZE, e)\n",
    "#         clear_output(wait=True)\n",
    "#         print()\n",
    "#         print(f\"Epoch {e} ================\")\n",
    "#         print(\"Loss f|g : ({:.3f}|{:.3f})\".format(loss_frame, loss_global))\n",
    "#         print(\"Acc f|g : ({:.3f}|{:.3f})\".format(correct_frame/(BATCH_SIZE*timestep), correct_global/BATCH_SIZE))\n",
    "#         print(\"==========================\")\n",
    "\n",
    "\n",
    "set_all_seed()\n",
    "import torch.utils.tensorboard.writer\n",
    "writer = torch.utils.tensorboard.writer.SummaryWriter()\n",
    "criterion_global = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(test_model.parameters(), lr=0.01)\n",
    "EPOCH = 10\n",
    "for e in range(EPOCH):\n",
    "    with tqdm(total=len(train_dl)) as pbar:\n",
    "        loss_sum_avg = []\n",
    "        acc_sum_avg = []\n",
    "        for data in train_dl:\n",
    "            inputs = data[\"motion_vector\"].to(\"cuda\")\n",
    "            global_labels = data[\"label\"].to(\"cuda\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output_global = test_model(inputs)\n",
    "            loss_global = criterion_global(output_global, global_labels)\n",
    "            loss_global.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                correct_global = (torch.argmax(output_global.softmax(dim=1), dim=1) == global_labels).float().sum()\n",
    "\n",
    "                writer.add_scalar(\"Batch-Loss-global/train\", loss_global.item(), e*len(train_dl)+len(loss_sum_avg))\n",
    "                writer.add_scalar(\"Batch-Accuracy-global/train\", correct_global/BATCH_SIZE, e*len(train_dl)+len(loss_sum_avg))\n",
    "\n",
    "                loss_sum_avg.append(loss_global.item())\n",
    "                acc_sum_avg.append(correct_global.item()/BATCH_SIZE)\n",
    "\n",
    "            pbar.set_description(\"Training: Epoch {} | Loss: {:.3f} | Accuracy {:.3f}\".format(e, sum(loss_sum_avg)/len(loss_sum_avg),  sum(acc_sum_avg)/len(acc_sum_avg)))\n",
    "            pbar.update()\n",
    "\n",
    "        writer.add_scalar(\"Epoch-Loss-global/train\", sum(loss_sum_avg)/len(loss_sum_avg), e)\n",
    "        writer.add_scalar(\"Epoch-Accuracy-global/train\", sum(acc_sum_avg)/len(acc_sum_avg), e)\n",
    "\n",
    "    with tqdm(total=len(test_dl)) as pbar:\n",
    "        loss_sum_avg = []\n",
    "        acc_sum_avg = []\n",
    "        for data in test_dl:\n",
    "            with torch.no_grad():\n",
    "                inputs = data[\"motion_vector\"].to(\"cuda\")\n",
    "                global_labels = data[\"label\"].to(\"cuda\")\n",
    "\n",
    "                output_global = test_model(inputs)\n",
    "                loss_global = criterion_global(output_global, global_labels)\n",
    "                correct_global = (torch.argmax(output_global.softmax(dim=1), dim=1) == global_labels).float().sum()\n",
    "\n",
    "                writer.add_scalar(\"Batch-Loss-global/test\", loss_global.item(), e*len(test_dl)+len(loss_sum_avg))\n",
    "                writer.add_scalar(\"Batch-Accuracy-global/test\", correct_global/BATCH_SIZE, e*len(test_dl)+len(loss_sum_avg))\n",
    "\n",
    "                loss_sum_avg.append(loss_global.item())\n",
    "                acc_sum_avg.append(correct_global.item()/BATCH_SIZE)\n",
    "\n",
    "                pbar.set_description(\"Validation: Epoch {} | Loss: {:.3f} | Accuracy {:.3f}\".format(e, sum(loss_sum_avg)/len(loss_sum_avg),  sum(acc_sum_avg)/len(acc_sum_avg)))\n",
    "                pbar.update()\n",
    "\n",
    "        writer.add_scalar(\"Epoch-Loss-global/test\", sum(loss_sum_avg)/len(loss_sum_avg), e)\n",
    "        writer.add_scalar(\"Epoch-Accuracy-global/test\", sum(acc_sum_avg)/len(acc_sum_avg), e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_linux_3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
