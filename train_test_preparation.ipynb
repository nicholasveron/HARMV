{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importables.preprocessing_managers import DatasetDictionary, PreprocessingManagers\n",
    "import importables.constants\n",
    "import importables.utilities\n",
    "import json\n",
    "import sklearn.model_selection\n",
    "import os\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NTU_ARD_PREGEN_ROOT = \"/mnt/c/Skripsi/dataset-pregen\"\n",
    "UCF101_ARD_PREGEN_ROOT = \"/mnt/c/Skripsi/UCF-101-pregen\"\n",
    "HMDB51_ARD_PREGEN_ROOT = \"/mnt/c/Skripsi/HMDB51-pregen\"\n",
    "DEFAULT_SPLIT = 0.3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NTU ARD Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dict = {\n",
    "    \"all\" :{\n",
    "        \"train\" : [],\n",
    "        \"test\" : []\n",
    "    },\n",
    "    \"single\":{\n",
    "        \"train\": [],\n",
    "        \"test\": []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_mapping = DatasetDictionary.Mappings.NTU_ACTION_RECOGNITION_DATASET\n",
    "pd_pregen = DatasetDictionary(os.path.join(NTU_ARD_PREGEN_ROOT,\"generated_dictionary.csv\"), curr_mapping).as_DataFrame()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "importables.utilities.Utilities.set_all_seed(importables.constants.RANDOM_SEED_BYTES)\n",
    "train_pd, test_pd = sklearn.model_selection.train_test_split(pd_pregen, test_size=DEFAULT_SPLIT, shuffle=True, stratify=pd_pregen[curr_mapping[\"A\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dict[\"all\"][\"train\"] = list(train_pd.sort_index().index)\n",
    "split_dict[\"all\"][\"test\"] = list(test_pd.sort_index().index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_pregen_filter = pd_pregen.loc[pd_pregen[curr_mapping[\"A\"]].isin(importables.constants.NTU_ACTION_DAILY_ACTIONS_SET)]\n",
    "importables.utilities.Utilities.set_all_seed(importables.constants.RANDOM_SEED_BYTES)\n",
    "train_pd, test_pd = sklearn.model_selection.train_test_split(pd_pregen_filter, test_size=DEFAULT_SPLIT, shuffle=True, stratify=pd_pregen_filter[curr_mapping[\"A\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dict[\"single\"][\"train\"] = list(train_pd.sort_index().index)\n",
    "split_dict[\"single\"][\"test\"] = list(test_pd.sort_index().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(NTU_ARD_PREGEN_ROOT,\"train_test_split.json\")\n",
    "with open(filepath, \"w\") as f:\n",
    "    f.write(json.JSONEncoder(indent=4).encode(split_dict))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCF101 ARD Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dict = {\n",
    "    \"preset1\" :{\n",
    "        \"train\" : [],\n",
    "        \"test\" : []\n",
    "    },\n",
    "    \"preset2\":{\n",
    "        \"train\": [],\n",
    "        \"test\": []\n",
    "    },\n",
    "    \"preset3\":{\n",
    "        \"train\": [],\n",
    "        \"test\": []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_mapping = DatasetDictionary.Mappings.UCF101_ACTION_RECOGNITION_DATASET\n",
    "pd_pregen = DatasetDictionary(os.path.join(UCF101_ARD_PREGEN_ROOT,\"generated_dictionary.csv\"), curr_mapping).as_DataFrame()\n",
    "name_adapter = DatasetDictionary.NameAdapters.UCF_101_ACTION_RECOGNITION_DATASET()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for preset_index in range(1,4):\n",
    "    train_idx_pd = pandas.read_csv(os.path.join(UCF101_ARD_PREGEN_ROOT,f\"ucfTrainTestlist/trainlist0{preset_index}.txt\"), sep=\" \", header=None, names=[\"file\", \"class\"])\n",
    "    train_pd = pd_pregen.loc[pd_pregen[\"GeneratedFileName\"].isin(\n",
    "                    train_idx_pd[\"file\"].apply(\n",
    "                        lambda x: name_adapter(\n",
    "                        str(x)\n",
    "                        .split(\"/\")[-1]\n",
    "                        .split(\".\")[0]\n",
    "                    )\n",
    "                    + \".h5\"))]\n",
    "\n",
    "    test_idx_pd = pandas.read_csv(os.path.join(UCF101_ARD_PREGEN_ROOT,f\"ucfTrainTestlist/testlist0{preset_index}.txt\"), sep=\" \", header=None, names=[\"file\", \"class\"])\n",
    "    test_pd = pd_pregen.loc[pd_pregen[\"GeneratedFileName\"].isin(\n",
    "                    test_idx_pd[\"file\"].apply(\n",
    "                        lambda x: name_adapter(\n",
    "                        str(x)\n",
    "                        .split(\"/\")[-1]\n",
    "                        .split(\".\")[0]\n",
    "                    )\n",
    "                    + \".h5\"))]\n",
    "\n",
    "    assert len(list(set(train_pd[\"GeneratedFileName\"]) & set(test_pd[\"GeneratedFileName\"]))) == 0\n",
    "\n",
    "    split_dict[f\"preset{preset_index}\"][\"train\"] = list(train_pd.sort_index().index)\n",
    "    split_dict[f\"preset{preset_index}\"][\"test\"] = list(test_pd.sort_index().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(UCF101_ARD_PREGEN_ROOT,\"train_test_split.json\")\n",
    "with open(filepath, \"w\") as f:\n",
    "    f.write(json.JSONEncoder(indent=4).encode(split_dict))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMDB51 ARD Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dict = {\n",
    "    \"preset1\" :{\n",
    "        \"train\" : [],\n",
    "        \"test\" : [],        \n",
    "        \"extra\" : [],\n",
    "    },\n",
    "    \"preset2\":{\n",
    "        \"train\": [],\n",
    "        \"test\": [],        \n",
    "        \"extra\": [],\n",
    "    },\n",
    "    \"preset3\":{\n",
    "        \"train\": [],\n",
    "        \"test\": [],        \n",
    "        \"extra\": [],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_mapping = DatasetDictionary.Mappings.HMDB51_ACTION_RECOGNITION_DATASET\n",
    "pd_pregen = DatasetDictionary(os.path.join(HMDB51_ARD_PREGEN_ROOT,\"generated_dictionary.csv\"), curr_mapping).as_DataFrame()\n",
    "name_adapter = DatasetDictionary.NameAdapters.HMDB_51_ACTION_RECOGNITION_DATASET()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for preset_index in range(1,4):\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    extra_indices = []\n",
    "\n",
    "    for class_name in importables.constants.HMDB51_DATASET_MAP.values():\n",
    "        idx_pd = pandas.read_csv(os.path.join(HMDB51_ARD_PREGEN_ROOT,f\"testTrainMulti_7030_splits/{class_name}_test_split{preset_index}.txt\"),index_col=False, sep=\" \", header=None, names=[\"file\", \"split\"])\n",
    "        train_idx_pd = idx_pd.loc[idx_pd[\"split\"] == 1]\n",
    "        test_idx_pd = idx_pd.loc[idx_pd[\"split\"] == 2]\n",
    "        extra_idx_pd = idx_pd.loc[idx_pd[\"split\"] == 0]\n",
    "\n",
    "        train_idx_pd = train_idx_pd[\"file\"].apply(\n",
    "                            lambda x: name_adapter(\n",
    "                            str(x)[:-4]\n",
    "                        )\n",
    "                        + \".h5\")\n",
    "        test_idx_pd = test_idx_pd[\"file\"].apply(\n",
    "                            lambda x: name_adapter(\n",
    "                            str(x)[:-4]\n",
    "                        )\n",
    "                        + \".h5\")\n",
    "        \n",
    "        extra_idx_pd = extra_idx_pd[\"file\"].apply(\n",
    "                            lambda x: name_adapter(\n",
    "                            str(x)[:-4]\n",
    "                        )\n",
    "                        + \".h5\")\n",
    "\n",
    "        train_pd = pd_pregen.loc[pd_pregen[\"GeneratedFileName\"].isin(train_idx_pd)]\n",
    "        test_pd = pd_pregen.loc[pd_pregen[\"GeneratedFileName\"].isin(test_idx_pd)]\n",
    "        extra_pd = pd_pregen.loc[pd_pregen[\"GeneratedFileName\"].isin(extra_idx_pd)]\n",
    "        \n",
    "        assert len(train_pd) == 70\n",
    "        assert len(test_pd) == 30\n",
    "\n",
    "        train_indices.extend(list(train_pd.sort_index().index))\n",
    "        test_indices.extend(list(test_pd.sort_index().index))\n",
    "        extra_indices.extend(list(extra_pd.sort_index().index))\n",
    "\n",
    "    assert len(list(set(train_indices) & set(test_indices) & set(extra_indices))) == 0\n",
    "\n",
    "    split_dict[f\"preset{preset_index}\"][\"train\"] = list(sorted(train_indices))\n",
    "    split_dict[f\"preset{preset_index}\"][\"test\"] = list(sorted(test_indices))\n",
    "    split_dict[f\"preset{preset_index}\"][\"extra\"] = list(sorted(extra_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(HMDB51_ARD_PREGEN_ROOT,\"train_test_split.json\")\n",
    "with open(filepath, \"w\") as f:\n",
    "    f.write(json.JSONEncoder(indent=4).encode(split_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_linux_3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
